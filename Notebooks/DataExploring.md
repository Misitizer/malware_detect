

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
```


```python
path_to_data = '../DataSets/train.csv'
# Путь с датасетом
```


```python
df = pd.read_csv('train.csv', nrows = 100000)
df.head()
# Загрузка датасета просмотр начала
```


```python
df.info()
# Cмотрим колонки и типы
```


```python
# Ищем колонки с наибольшим количеством пропущенных данных
(df.isnull().sum()/df.shape[0]).sort_values(ascending=False)
```


```python
drops = []
# Таблицы, которые считаю ненужными запишу в этот массив
```


```python
drops.append('PuaMode')
drops.append('Census_ProcessorClass')
drops.append('DefaultBrowsersIdentifier')
# Те столбцы, у которых больше 95% пропущенных данных исключаем
```


```python
columns = df.columns.to_list()
for col in columns:
  print(df[col].value_counts())
  print('---------------------------------------------------------------------')
```


```python
table = []
for col in columns[1:]:
    data_col_stat = df[col].value_counts()
    unique = df[col].nunique()
    most = df[col].value_counts(normalize=True).values[0]*100
    if most > 99:
        if col not in drops:
            drops.append(col)
    table.append((col, unique, most))
# Cмотрим на уникальные данные и процент самого встречаемого 
# компонетнта и эти столбцы подчистим
```


```python
table_df = pd.DataFrame(table, columns = ['Column','Unique Values', 'Most Popular'])
table_df.sort_values('Most Popular',ascending=False)
# Более наглядное представление данных в предыдущем блоке


```


```python
df['HasDetections'].value_counts()


```


```python
for col in drops:
  del df[col]
print(df.shape)
# Удаляем ненужные данные

```


```python
del df['MachineIdentifier']
# Удаляем все айдишники, т.к. они все уникальны
```


```python
plt.figure(figsize = (50,50))
sns.heatmap(df.corr(), cmap='RdBu_r', annot=True, center=0.0)
plt.show()
# смотрим какие данные между собой сильно коррелируют
```


```python
print(df['Census_OSInstallLanguageIdentifier'].nunique())
print(df['Census_OSUILocaleIdentifier'].nunique())
# Выбираем ту колонку, где больше уникальных значений
drops.append('Census_OSInstallLanguageIdentifier')
```


```python
del df['Census_OSInstallLanguageIdentifier']
```


```python
del df['HasDetections']
```


```python
columns = df.columns.to_list()
category = []
numeric = []
target = 'HasDetections'
```


```python
for col in columns[:-1]:
  if df[col].dtype == 'object':
    category.append(col)
  else:
    numeric.append(col)


```


```python
print(category)

```
